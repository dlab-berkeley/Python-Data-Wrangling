{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Data Wrangling with `pandas`: Part 2\n",
    "\n",
    "* * * \n",
    "<div class=\"alert alert-success\">  \n",
    "    \n",
    "### Learning Objectives \n",
    "    \n",
    "* Gain familiarity with `pandas` and the core `DataFrame` object\n",
    "* Apply core data wrangling techniques in `pandas`\n",
    "* Understand the flexibility of the `pandas` library\n",
    "</div>\n",
    "\n",
    "### Icons Used in This Notebook\n",
    "üîî **Question**: A quick question to help you understand what's going on.<br>\n",
    "ü•ä **Challenge**: Interactive exercise. We'll work through these in the workshop!<br>\n",
    "üí° **Tip**: How to do something a bit more efficiently or effectively.<br>\n",
    "‚ö†Ô∏è **Warning:** Heads-up about tricky stuff or common mistakes.<br>\n",
    "üé¨ **Demo**: Showing off something more advanced ‚Äì so you know what Pandas can be used for!<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sections\n",
    "4. [Missing Data](#missing)\n",
    "5. [Sorting Values](#sorting)\n",
    "6. [Merging](#merging)\n",
    "7. [Grouping](#grouping)\n",
    "8. [Visualization](#viz)\n",
    "\n",
    "Let's start back up by importing our libraries and loading up our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the unemployment dataset\n",
    "unemployment = pd.read_csv('../data/cleaned_country_totals.csv')\n",
    "# This is some formatting that's out of scope\n",
    "unemployment['date'] = pd.to_datetime(unemployment['date'])\n",
    "\n",
    "# Open the countries dataset\n",
    "countries_url = 'https://raw.githubusercontent.com/dlab-berkeley/Python-Data-Wrangling/main/data/countries.csv'\n",
    "countries = pd.read_csv(countries_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='missing'></a>\n",
    "# Missing Values\n",
    "When working with a new data source, it's good to get an idea of how much information is missing. `pandas` provides various methods for exploring and dealing with \"missing-ness\", one of which is `.isna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.isna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `.isna()` method returns a corresponding boolean value for each entry in the `unemployment` DataFrame. In Python, `True` is equivalent to 1 and `False` is equivalent to 0. Thus, when we add up the results by column (with `.sum()`), we get a count for the **total** number of missing values by column::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a very helpful trick, and it shows us that the only column with missing values is `unemployment_rate`.\n",
    "\n",
    "There are a wide variety of approaches to dealing with missing data. One basic approach would be to drop any row with a missing unemployment rate record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.dropna(subset=['unemployment_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simply running the `.dropna()` method actually doesn't alter our data -- it makes a copy then drops the missing rows for that copy. In order to save our alteration, we'll need to re-define the `unemployment` DataFrame with our altered copy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment = unemployment.dropna(subset=['unemployment_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**üí° Tip:** Note that the brackets `[]` are needed in the `dropna()` method because the subset parameter expects a list of column names. Even if you're specifying just one column, it still needs to be enclosed in brackets to indicate that it's a list. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='sorting'></a>\n",
    "# Sorting Values\n",
    "\n",
    "We've been working with data about unemployment rates, so it would probably be useful to know what the highest unemployment rates are in this data. For this, we'll use the `sort_values()` method to sort the data. We chain `.head()` onto the end of this so that we only see the first five rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.sort_values(by='date', ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code creates a copy of the `DataFrame`, sorted in **descending** order (note `ascending=False`), and prints the first five rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 5\n",
    "Let's use sorting to answer a practical question:  \n",
    "\n",
    "<span style=\"color:purple\">Which country has the highest unemployment rate in our data?  \n",
    "</span>\n",
    "<details><summary><a>Click for hint</a></summary>\n",
    "1. Use <code>.sort_values()</code> to sort this data based on the unemployment rate using descending order<br>\n",
    "2. Select the top row using <code>.head()</code> with an argument for number of rows<br>\n",
    "</details>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='merging'></a>\n",
    "# Merging DataFrames\n",
    "\n",
    "Our `unemployment` has a lot of interesting information, but it is unfortunately missing any full country names. We have that information in the `countries` DataFrame, but we need to find a way of combining it with `unemployment`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the data we need is stored in two separate files, we'll want to merge the data somehow. Let's determine which column we can use to join this data by taking a look at `unemployment`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These two DataFrames seem to have a similar `country` column, with two character codes for each country. Let's try doing a merge of these two datasets based on the `country` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` includes an easy-to-use merge function that accepts two DataFrames and a column to merge them on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_merged = pd.merge(unemployment, countries, on='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_merged.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='grouping'></a>\n",
    "# Grouping and Aggregating Data\n",
    "\n",
    "What if we'd like to know how many observations exist for each country? To do so, we need to group the countries, then count how many times each one occurs. In other words, we're going to **group** our data **by** a specific column, and calculate some quantity within each group. The \"group-by\" operation is a fundamental technique used with tabular data.  \n",
    "\n",
    "\n",
    "(For those who have used spreadsheet software like Excel, you might recognize that we are essentially talking about making a \"Pivot-Table\")\n",
    "\n",
    "## Simple Grouping with `.value_counts()`\n",
    "For simple grouping operations, we can use the handy `.value_counts()` method. We typically run this on a single column, and it will return a table showing how many observations there are for each unique value in the column. The following graphic represents the basics of the operations.\n",
    "<img src=\"../images/valcounts.svg\" align=\"left\" width=\"400\" alt=\"diagram of pandas datafram\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_merged['name_en'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that we have a lot of observations of data for Italy, France, Sweden, etc. and very few observations for Turkey and Estonia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 6\n",
    "Try using `.value_counts()` on the DataFrame to find out how many observations are from EU versus non-EU records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complex grouping with `.groupby()`\n",
    "What if we want to do something more complex, like find out **what was the average unemployment rate for EU and non-EU countries?**. `.value_counts()` groups data then counts it, but we need a method that can group data then average it.\n",
    "\n",
    "This sort of question is a typical use case for `.groupby()` -- which allows us to group data then apply any **aggregate** function we want -- count, average, min, max, median, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our example, we want to find out the average unemployment rate for EU and non-EU countries, so we will group our data based on `country_group`. Here is a graphical representation of our goal:    \n",
    "<img src=\"../images/groupby.svg\" align=\"left\" width=\"500\" alt=\"diagram of pandas datafram\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the method, `.groupby()`. This doesn't actually return data or output -- it just groups the data.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_merged.groupby('country_group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have to select a column of data and specify an aggregate function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_merged.groupby('country_group')['unemployment_rate'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dissecting the code, we told `pandas`:\n",
    "1. <code>unemployment_merged<code><mark style=\"background: yellow\">.groupby('country_group')</mark>['unemployment_rate'].mean()</code>\n",
    "\n",
    "    Group all of our rows based on the unique values of the `country_group` column -- EU, non-EU\n",
    "    \n",
    "2. <code>unemployment_merged<code>.groupby('country_group')<mark style=\"background: yellow\">['unemployment_rate']</mark>.mean()</code>\n",
    "\n",
    "    Select the `unemployment_rate` column\n",
    "\n",
    "2. <code>unemployment_merged<code>.groupby('country_group')['unemployment_rate']<mark style=\"background: yellow\">.mean()</mark></code>\n",
    "\n",
    "   Compute the average of the selected column (`unemployment_rate`) for each group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm this behavior using boolean indexing as well. If we index to only those records from EU countries, select the `unemployment_rate` column, then compute the average, we should get 8.3, the same value computed with groupby:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_index = unemployment_merged['country_group'] == 'eu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_merged.loc[boolean_index, 'unemployment_rate'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strengths of `.groupby()` relative to using boolean indexing are that `groupby()` scales very well to scenarios with many groups, and it requires much less code."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge 7\n",
    "\n",
    "Use `.groupby()` to find the maximum unemployment rate for each country. Sort your results from largest to smallest.\n",
    "\n",
    "Use the example above for guidance. \n",
    "<details><summary><a>Click for hint</a></summary>\n",
    "1. First, use <code>groupby()</code> to group on \"name_en\". <br>\n",
    "2. Then, select the \"unemployment_rate\" column,<br>\n",
    "3. Aggregate by using <code>.max()</code> to get the max value.<br>\n",
    "4. Chain on the method <code>.sort_values(ascending=False)</code>.\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='viz'></a>\n",
    "# Data Visualization\n",
    "In the last challenge, you created an interesting table showing the all-time maximum unemployment rate that each country has experienced. Let's visualize that table as a bar chart to make it easier to present.\n",
    "\n",
    "There are various ways to approach data visualization in Python -- we'll cover simple plotting in `pandas`, which draws on functionality from the `matplotlib` library.\n",
    "\n",
    "First, we'll define a variable, `grouped`, with the table you just made:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = unemployment_merged.groupby('name_en')['unemployment_rate'].max().sort_values(ascending=False)\n",
    "grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot it. In `pandas`, visualization is as simple as calling the `.plot()` method, then supplying optional arguments (here I supplied `kind=\"barh\"` to make a horizontal bar chart rather than the default line-chart). The following is the maximum unemployment rate across countries in the data for each year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.plot(kind='barh')\n",
    "\n",
    "# We add plt.show() to properly render the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try another plot. Our full DataFrame is what's called a time-series -- we have repeated observations of various countries' unemployment rates over time. We typically plot time-series using line-plots, so let's make a line plot examining Spain and Portugal's unemployment rates.  \n",
    "\n",
    "To make this sort of plot simpler, we'll start by making our date column into the DataFrame's index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_merged = unemployment_merged.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unemployment_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also use boolean indexing to select on those observations that are for Spain. We'll save that as a new DataFrame, `spain`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spain = unemployment_merged[unemployment_merged['name_en'] == 'Spain']\n",
    "spain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can easily access Spain's unemployment rate, with the date for each observation included as the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spain['unemployment_rate']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's repeat the same boolean indexing we used for Spain, but now for Portugal:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portugal = unemployment_merged[unemployment_merged['name_en'] == 'Portugal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "portugal.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take advantage of the `.plot()` function, simply calling `spain['unemployment_rate'].plot()`. We don't need to supply any argument to `.plot()` since we are using the default plot style -- a line-plot. We do add some other commands to add a y-axis label and render the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spain['unemployment_rate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spain['unemployment_rate'].plot()\n",
    "\n",
    "# We add plt.show() to properly render the chart\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layering plots will involve simply calling multiple `.plot()` commands in the same Jupyter cell. We can add some basic styling as well, such as labels, a legend, and a title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot commands\n",
    "spain['unemployment_rate'].plot()\n",
    "portugal['unemployment_rate'].plot()\n",
    "\n",
    "# Styling\n",
    "plt.legend([\"Spain\", \"Portugal\"])\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Spain and Portugal Unemployment Rates\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéâ Well Done!\n",
    "\n",
    "This workshop series took us through the basics of data analysis using `pandas`. We indexed data using boolean logic, grouped data to perform conditional analyses, and we create basic but informative visualizations.\n",
    "\n",
    "## More Workshops!\n",
    "\n",
    "D-Lab teaches workshops that allow you to practice more with DataFrames and visualization.\n",
    "\n",
    "- To learn other fundamental Python topics, check out D-Lab's [Python Intermediate workshop](https://github.com/dlab-berkeley/Python-Intermediate-Pilot).\n",
    "- To learn more about data visualization, check out D-Lab's [Python Data Visualization workshop](https://github.com/dlab-berkeley/Python-Data-Visualization)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
